import requests
import json
import time
import re
from geopy.geocoders import Nominatim
from bs4 import BeautifulSoup

# ğŸ“Œ ConfiguraciÃ³n del geolocalizador
geolocalizador = Nominatim(user_agent="geo_scraper")

# ğŸ“Œ FunciÃ³n para obtener coordenadas
def obtener_coordenadas(ubicacion):
    """Convierte una ciudad/localidad en coordenadas (lat, lon)"""
    try:
        ubicacion_info = geolocalizador.geocode(f"{ubicacion}, Argentina")
        if ubicacion_info:
            return [ubicacion_info.longitude, ubicacion_info.latitude]
    except:
        return None
    return None

# ğŸ“Œ FunciÃ³n para estandarizar ubicaciones
def estandarizar_ubicacion(texto):
    """Busca y estandariza la ubicaciÃ³n en el formato (ciudad, provincia)"""
    provincias = {
        "buenos aires": "Buenos Aires",
        "santa fe": "Santa Fe",
        "cordoba": "Cordoba",
        "mendoza": "Mendoza",
        "entre rios": "Entre Rios",
        "chaco": "Chaco",
        "misiones": "Misiones",
        "corrientes": "Corrientes",
        "neuquen": "Neuquen",
        "rio negro": "Rio Negro",
        "tucuman": "Tucuman"
    }

    ubicacion = None
    for provincia in provincias:
        if provincia in texto.lower():
            coincidencias = re.findall(r"([A-Z][a-z]+) (?:de |en |, )?" + provincia, texto, re.IGNORECASE)
            if coincidencias:
                localidad = coincidencias[0].strip()
                ubicacion = f"{localidad}, {provincias[provincia]}"
            else:
                ubicacion = provincias[provincia]

    return ubicacion

# ğŸ“Œ FunciÃ³n para buscar enlaces en Google (placeholder)
def buscar_en_google(consulta):
    """SimulaciÃ³n de bÃºsqueda en Google (debe integrarse con un servicio real)"""
    print(f"ğŸ” Simulando bÃºsqueda en Google: {consulta}")
    return []  # âš  Actualmente no devuelve resultados

# ğŸ“Œ FunciÃ³n para extraer datos de una noticia
def extraer_datos_noticia(url):
    """Extrae datos clave de una noticia"""
    try:
        response = requests.get(url, headers={'User-Agent': 'Mozilla/5.0'})
        if response.status_code != 200:
            print(f"âš ï¸ No se pudo obtener la noticia: {url}")
            return None

        sopa = BeautifulSoup(response.text, "html.parser")
        texto = sopa.get_text().lower()

        # ğŸ“Œ Extraer tÃ­tulo
        titulo = sopa.title.string.strip() if sopa.title else "TÃ­tulo desconocido"

        # ğŸ“Œ Extraer fecha (solo aÃ±o)
        fecha = "Desconocida"
        for palabra in texto.split():
            if palabra.isdigit() and len(palabra) == 4:
                fecha = palabra
                break

        # ğŸ“Œ Extraer ubicaciÃ³n
        ubicacion = estandarizar_ubicacion(texto)
        coordenadas = obtener_coordenadas(ubicacion) if ubicacion else None

        # ğŸ“Œ Buscar menciÃ³n a agua
        menciona_agua = any(agua in texto for agua in ["rÃ­o", "laguna", "napas", "agua", "contaminaciÃ³n hÃ­drica"])

        # ğŸ“Œ Buscar agroquÃ­micos
        AGROQUIMICOS_CATEGORIAS = {
            "herbicida": ["glifosato", "atrazina", "2,4-D"],
            "insecticida": ["clorpirifos", "imidacloprid", "cipermetrina"],
            "fungicida": ["mancozeb", "carbendazim", "triazol"]
        }
        agroquimicos = []
        categoria_filtro = []
        for categoria, lista in AGROQUIMICOS_CATEGORIAS.items():
            for quimico in lista:
                if quimico in texto:
                    agroquimicos.append(quimico)
                    categoria_filtro.append(categoria)

        # ğŸ“Œ Detectar protestas o denuncias
        menciona_protesta = any(palabra in texto for palabra in ["denuncia", "protesta", "marcha", "juicio", "vecinos", "movilizaciÃ³n"])

        # ğŸ“Œ Estructurar la noticia
        noticia = {
            "conflicto": titulo,
            "url": url,
            "fecha": fecha,
            "fuente": url.split("/")[2],
            "ubicacion": ubicacion if ubicacion else "Desconocida",
            "coordenadas": coordenadas if coordenadas else [0, 0],  # ğŸ”¹ Siempre devuelve coordenadas vÃ¡lidas
            "agua": "SÃ­" if menciona_agua else "No",
            "agroquimicos": ", ".join(agroquimicos),
            "categoria_filtro": ", ".join(categoria_filtro),
            "protestas": "SÃ­" if menciona_protesta else "No"
        }

        print(f"âœ… Noticia extraÃ­da: {noticia}")
        return noticia

    except Exception as e:
        print(f"âŒ Error al extraer la noticia: {url} - {e}")
        return None

# ğŸ“Œ Cargar datos existentes en el GeoJSON
try:
    with open("ConflictosGeorref_final_DEF.geojson", "r", encoding="utf-8") as f:
        datos = json.load(f)
except FileNotFoundError:
    datos = {"type": "FeatureCollection", "features": []}

# ğŸ“Œ Buscar noticias en Google para todas las fuentes
nuevas_noticias = []
consultas_google = [f"contaminaciÃ³n por agroquÃ­micos site:{fuente}" for fuente in FUENTES]

for consulta in consultas_google:
    enlaces_google = buscar_en_google(consulta)
    for enlace in enlaces_google:
        noticia = extraer_datos_noticia(enlace)
        if noticia:
            nuevas_noticias.append(noticia)

# ğŸ“Œ Agregar noticias nuevas al GeoJSON
urls_existentes = {f["properties"]["url"] for f in datos["features"] if "url" in f["properties"]}

for noticia in nuevas_noticias:
    if noticia["url"] not in urls_existentes:
        datos["features"].append({
            "type": "Feature",
            "properties": noticia,
            "geometry": {
                "type": "Point",
                "coordinates": noticia["coordenadas"]
            }
        })
        print(f"âœ… Noticia agregada al GeoJSON: {noticia['conflicto']} - {noticia['url']}")

# ğŸ“Œ Guardar el nuevo GeoJSON
with open("ConflictosGeorref_final_DEF.geojson", "w", encoding="utf-8") as f:
    json.dump(datos, f, indent=4, ensure_ascii=False)

print("âœ… Base de datos actualizada con nuevas noticias.")
